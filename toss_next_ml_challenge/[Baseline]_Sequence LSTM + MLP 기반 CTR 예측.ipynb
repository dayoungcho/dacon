{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "20abd96a-4eb5-483d-b3d9-32e1c1340ece",
      "metadata": {
        "id": "20abd96a-4eb5-483d-b3d9-32e1c1340ece"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a593bbe1-b8a5-4a40-b46f-4ff25f132b86",
      "metadata": {
        "id": "a593bbe1-b8a5-4a40-b46f-4ff25f132b86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d1e7a28-1d18-40a7-9d19-1dcdab7537ec",
      "metadata": {
        "id": "7d1e7a28-1d18-40a7-9d19-1dcdab7537ec"
      },
      "source": [
        "## Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d13d5928-880f-4b88-8dfa-dc791e930001",
      "metadata": {
        "id": "d13d5928-880f-4b88-8dfa-dc791e930001"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'BATCH_SIZE': 4096,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE': 1e-3,\n",
        "    'SEED' : 42\n",
        "}\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "99aa02da-d89b-4a18-8344-261a413bac83",
      "metadata": {
        "id": "99aa02da-d89b-4a18-8344-261a413bac83"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6421efbe-70c6-4aeb-946c-be1556e7743d",
      "metadata": {
        "id": "6421efbe-70c6-4aeb-946c-be1556e7743d"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H0CAd9y-W_f",
        "outputId": "da541a60-db5a-4d15-e0f4-1ca33e15cf76"
      },
      "id": "7H0CAd9y-W_f",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/toss_dacon')"
      ],
      "metadata": {
        "id": "mDttDU_2-kAj"
      },
      "id": "mDttDU_2-kAj",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "all_train = pl.scan_parquet(\"./train.parquet\")\n",
        "test = pl.read_parquet(\"./test.parquet\")"
      ],
      "metadata": {
        "id": "OVz14hb4J6lF"
      },
      "id": "OVz14hb4J6lF",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clicked_1 = all_train.filter(pl.col(\"clicked\")==1).collect()\n",
        "\n",
        "n_for_clicked_0 = len(clicked_1) * 2\n",
        "clicked_0 = all_train.filter(pl.col(\"clicked\")==0).with_columns(\n",
        "    (pl.col(\"inventory_id\").hash(seed=42)).alias(\"random_val\")).sort(\"random_val\").head(n_for_clicked_0).drop(\"random_val\")\n",
        "\n",
        "clicked_0 = clicked_0.collect()\n",
        "\n",
        "train = pl.concat([clicked_1, clicked_0]).sample(frac=1, shuffle=True, seed=42).reset_index(drop=True)\n",
        "\n",
        "print(train.shape)\n",
        "print(train.get_column(\"clicked\").value_counts())"
      ],
      "metadata": {
        "id": "AKvWQmSEL_Vd"
      },
      "id": "AKvWQmSEL_Vd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clicked_1 = pl.scan_parquet(\"./train.parquet\").filter(pl.col(\"clicked\")==1)\n",
        "clicked_0 = pl.scan_parquet(\"./train.parquet\").filter(pl.col(\"clicked\")==0)\n",
        "\n",
        "# Collect the LazyFrames to DataFrames before sampling\n",
        "clicked_1_df = clicked_1.collect()\n",
        "clicked_0_df = clicked_0.collect()\n",
        "\n",
        "# Apply sample after collecting\n",
        "clicked_0_sampled = clicked_0_df.sample(n=len(clicked_1_df)*2, seed=42)\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "train = pl.concat([clicked_1_df, clicked_0_sampled], how=\"vertical\").sample(frac=1, seed=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "okmvDGI3DFO4"
      },
      "id": "okmvDGI3DFO4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5cb80e25-5b02-43da-aa4f-5ca16cd7802e",
      "metadata": {
        "id": "5cb80e25-5b02-43da-aa4f-5ca16cd7802e"
      },
      "source": [
        "## Data Down-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "151fc664-faa0-4951-bbbb-8b92f1ee3bff",
      "metadata": {
        "id": "151fc664-faa0-4951-bbbb-8b92f1ee3bff"
      },
      "outputs": [],
      "source": [
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Train clicked:0:\", train[train['clicked']==0].shape)\n",
        "print(\"Train clicked:1:\", train[train['clicked']==1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c188a0d4-f60a-422c-bb53-ae8eba8744d6",
      "metadata": {
        "id": "c188a0d4-f60a-422c-bb53-ae8eba8744d6"
      },
      "source": [
        "## Data Column Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ecc473-4bd8-4304-9d68-a5c01f4bbe11",
      "metadata": {
        "id": "c7ecc473-4bd8-4304-9d68-a5c01f4bbe11"
      },
      "outputs": [],
      "source": [
        "# Target / Sequence\n",
        "target_col = \"clicked\"\n",
        "seq_col = \"seq\"\n",
        "\n",
        "# 학습에 사용할 피처: ID/seq/target 제외, 나머지 전부\n",
        "FEATURE_EXCLUDE = {target_col, seq_col, \"ID\"}\n",
        "feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]\n",
        "\n",
        "print(\"Num features:\", len(feature_cols))\n",
        "print(\"Sequence:\", seq_col)\n",
        "print(\"Target:\", target_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "426899fa-b4f3-480d-b7de-8d7e811ad4f8",
      "metadata": {
        "id": "426899fa-b4f3-480d-b7de-8d7e811ad4f8"
      },
      "source": [
        "## Define Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3c0b13b-3a81-4a2e-a753-1f9d8aa467ea",
      "metadata": {
        "id": "c3c0b13b-3a81-4a2e-a753-1f9d8aa467ea"
      },
      "outputs": [],
      "source": [
        "class ClickDataset(Dataset):\n",
        "    def __init__(self, df, feature_cols, seq_col, target_col=None, has_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.feature_cols = feature_cols\n",
        "        self.seq_col = seq_col\n",
        "        self.target_col = target_col\n",
        "        self.has_target = has_target\n",
        "\n",
        "        # 비-시퀀스 피처: 전부 연속값으로\n",
        "        self.X = self.df[self.feature_cols].astype(float).fillna(0).values\n",
        "\n",
        "        # 시퀀스: 문자열 그대로 보관 (lazy 파싱)\n",
        "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
        "\n",
        "        if self.has_target:\n",
        "            self.y = self.df[self.target_col].astype(np.float32).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.X[idx], dtype=torch.float)\n",
        "\n",
        "        # 전체 시퀀스 사용 (빈 시퀀스만 방어)\n",
        "        s = self.seq_strings[idx]\n",
        "        if s:\n",
        "            arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
        "        else:\n",
        "            arr = np.array([], dtype=np.float32)\n",
        "\n",
        "        if arr.size == 0:\n",
        "            arr = np.array([0.0], dtype=np.float32)  # 빈 시퀀스 방어\n",
        "\n",
        "        seq = torch.from_numpy(arr)  # shape (seq_len,)\n",
        "\n",
        "        if self.has_target:\n",
        "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
        "            return x, seq, y\n",
        "        else:\n",
        "            return x, seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b95f1cd-e8e8-4420-ad26-c639e36e472f",
      "metadata": {
        "id": "7b95f1cd-e8e8-4420-ad26-c639e36e472f"
      },
      "outputs": [],
      "source": [
        "def collate_fn_train(batch):\n",
        "    xs, seqs, ys = zip(*batch)\n",
        "    xs = torch.stack(xs)\n",
        "    ys = torch.stack(ys)\n",
        "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
        "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
        "    seq_lengths = torch.clamp(seq_lengths, min=1)  # 빈 시퀀스 방지\n",
        "    return xs, seqs_padded, seq_lengths, ys\n",
        "\n",
        "def collate_fn_infer(batch):\n",
        "    xs, seqs = zip(*batch)\n",
        "    xs = torch.stack(xs)\n",
        "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
        "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
        "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
        "    return xs, seqs_padded, seq_lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6649f6ff-cb10-45ee-b787-d2e7e652c871",
      "metadata": {
        "id": "6649f6ff-cb10-45ee-b787-d2e7e652c871"
      },
      "source": [
        "## Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9144bc61-0942-4ed3-bb52-e347d571ad4a",
      "metadata": {
        "id": "9144bc61-0942-4ed3-bb52-e347d571ad4a"
      },
      "outputs": [],
      "source": [
        "class TabularSeqModel(nn.Module):\n",
        "    def __init__(self, d_features, lstm_hidden=32, hidden_units=[1024, 512, 256, 128], dropout=0.2):\n",
        "        super().__init__()\n",
        "        # 모든 비-시퀀스 피처에 BN\n",
        "        self.bn_x = nn.BatchNorm1d(d_features)\n",
        "        # seq: 숫자 시퀀스 → LSTM\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden, batch_first=True)\n",
        "\n",
        "        # 최종 MLP\n",
        "        input_dim = d_features + lstm_hidden\n",
        "        layers = []\n",
        "        for h in hidden_units:\n",
        "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            input_dim = h\n",
        "        layers += [nn.Linear(input_dim, 1)]\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x_feats, x_seq, seq_lengths):\n",
        "        # 비-시퀀스 피처\n",
        "        x = self.bn_x(x_feats)\n",
        "\n",
        "        # 시퀀스 → LSTM (pack)\n",
        "        x_seq = x_seq.unsqueeze(-1)  # (B, L, 1)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            x_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        _, (h_n, _) = self.lstm(packed)\n",
        "        h = h_n[-1]                  # (B, lstm_hidden)\n",
        "\n",
        "        z = torch.cat([x, h], dim=1)\n",
        "        return self.mlp(z).squeeze(1)  # logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c6ad06-d840-4ac3-b565-4d2450c0af39",
      "metadata": {
        "id": "b2c6ad06-d840-4ac3-b565-4d2450c0af39"
      },
      "source": [
        "## Train / Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d94d11-f7b9-449e-b631-e70224df92c9",
      "metadata": {
        "id": "f9d94d11-f7b9-449e-b631-e70224df92c9"
      },
      "outputs": [],
      "source": [
        "def train_model(train_df, feature_cols, seq_col, target_col,\n",
        "                batch_size=512, epochs=3, lr=1e-3, device=\"cuda\"):\n",
        "\n",
        "    # 1) split\n",
        "    tr_df, va_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "    # 2) Dataset / Loader (l_max 인자 제거)\n",
        "    train_dataset = ClickDataset(tr_df, feature_cols, seq_col, target_col, has_target=True)\n",
        "    val_dataset   = ClickDataset(va_df, feature_cols, seq_col, target_col, has_target=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=collate_fn_train)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn_train)\n",
        "\n",
        "    # 3) 모델\n",
        "    d_features = len(feature_cols)\n",
        "    model = TabularSeqModel(d_features=d_features, lstm_hidden=64, hidden_units=[256,128], dropout=0.2).to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # 4) Loop\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for xs, seqs, seq_lens, ys in tqdm(train_loader, desc=f\"Train Epoch {epoch}\"):\n",
        "            xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xs, seqs, seq_lens)\n",
        "            loss = criterion(logits, ys)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * ys.size(0)\n",
        "        train_loss /= len(train_dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for xs, seqs, seq_lens, ys in tqdm(val_loader, desc=f\"Val Epoch {epoch}\"):\n",
        "                xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
        "                logits = model(xs, seqs, seq_lens)\n",
        "                loss = criterion(logits, ys)\n",
        "                val_loss += loss.item() * len(ys)\n",
        "        val_loss /= len(val_dataset)\n",
        "\n",
        "        print(f\"[Epoch {epoch}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0999f03-85ca-4eaf-bea0-822cda393d29",
      "metadata": {
        "id": "d0999f03-85ca-4eaf-bea0-822cda393d29"
      },
      "source": [
        "## Run!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b730bdf4-9697-40b1-b53b-1c10380ff43d",
      "metadata": {
        "id": "b730bdf4-9697-40b1-b53b-1c10380ff43d"
      },
      "outputs": [],
      "source": [
        "model = train_model(\n",
        "    train_df=train,\n",
        "    feature_cols=feature_cols,\n",
        "    seq_col=seq_col,\n",
        "    target_col=target_col,\n",
        "    batch_size=CFG['BATCH_SIZE'],\n",
        "    epochs=CFG['EPOCHS'],\n",
        "    lr=CFG['LEARNING_RATE'],\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5421c1-a18d-43de-934e-d0ee5af34594",
      "metadata": {
        "id": "8c5421c1-a18d-43de-934e-d0ee5af34594"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f64e9288-e35d-4e03-bb41-2c4d1fd5ccaf",
      "metadata": {
        "id": "f64e9288-e35d-4e03-bb41-2c4d1fd5ccaf"
      },
      "outputs": [],
      "source": [
        "# 1) Dataset/Loader\n",
        "test_ds = ClickDataset(test, feature_cols, seq_col, has_target=False)\n",
        "test_ld = DataLoader(test_ds, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_infer)\n",
        "\n",
        "# 2) Predict\n",
        "model.eval()\n",
        "outs = []\n",
        "with torch.no_grad():\n",
        "    for xs, seqs, lens in tqdm(test_ld, desc=\"Inference\"):\n",
        "        xs, seqs, lens = xs.to(device), seqs.to(device), lens.to(device)\n",
        "        outs.append(torch.sigmoid(model(xs, seqs, lens)).cpu())\n",
        "\n",
        "test_preds = torch.cat(outs).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "addc0a92-05f9-4be6-9e45-cc52240afc3e",
      "metadata": {
        "id": "addc0a92-05f9-4be6-9e45-cc52240afc3e"
      },
      "source": [
        "## Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757f01bc-51a2-46bf-983f-a54e91abe222",
      "metadata": {
        "id": "757f01bc-51a2-46bf-983f-a54e91abe222"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['clicked'] = test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289fc0a5-d97a-4cd6-abfb-245b7383ac34",
      "metadata": {
        "id": "289fc0a5-d97a-4cd6-abfb-245b7383ac34"
      },
      "outputs": [],
      "source": [
        "submit.to_csv('./baseline_submit.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}